{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results reproducible\n",
    "#seed = 1235\n",
    "#np.random.seed(seed)\n",
    "#tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "data_X = np.load('male_array_1.npy')\n",
    "data_y = np.load('male_array_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def formattingData(data_X, data_y, test_size, label):\n",
    "    data_y = pd.DataFrame(data_y)\n",
    "    data_y.columns = ['혈당', '수축기혈압', '이완기혈압', '총콜레스테롤','HDL콜레스테롤', 'LDL콜레스테롤', '혈색소', '요단백']\n",
    "\n",
    "    X = pd.DataFrame(data_X)\n",
    "    y = data_y[label]\n",
    "\n",
    "    X[label] = y\n",
    "    n = len(X[X[label] == 2])\n",
    "    temp = pd.concat([X[X[label] == 1][:n], X[X[label] == 2][:n]], axis = 0)\n",
    "    y = pd.get_dummies(temp[label])\n",
    "    y = np.array(y)\n",
    "    X = np.array(temp[[0,1,2,3,4,5]])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    n_input = len(X_train[0])\n",
    "    n_output = len(y_train[0])\n",
    "    \n",
    "    return  X_train, X_test, y_train, y_test, n_input, n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitPlaceholders(n_input, n_output):\n",
    "    with tf.name_scope(\"input\") as scope:\n",
    "        input_placeholder = tf.placeholder(shape=[None, n_input], dtype=tf.float32)\n",
    "\n",
    "    with tf.name_scope(\"target\") as scope:\n",
    "        target_placeholder = tf.placeholder(shape=[None, n_output], dtype=tf.float32)\n",
    "        \n",
    "    keep_prob_placeholder = tf.placeholder(\"float\")\n",
    "    \n",
    "    return input_placeholder, target_placeholder, keep_prob_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations\n",
    "def Create3LayerDNN(input_placeholder,\n",
    "                    n_input, n_output,\n",
    "                    input_layer_nodes,\n",
    "                    hidden_layer_nodes1, hidden_layer_nodes2, hidden_layer_nodes3,\n",
    "                    output_layer_nodes):\n",
    "    \n",
    "    # first hidden layer\n",
    "    with tf.name_scope(\"weight1\") as scope:\n",
    "        w1 = tf.get_variable(\"w1\", shape=[input_layer_nodes, hidden_layer_nodes1], initializer=tf.keras.initializers.he_normal())\n",
    "    with tf.name_scope(\"bias1\")as scope:\n",
    "        b1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes1]))\n",
    "    with tf.name_scope(\"layer1\") as scope:\n",
    "        hidden_output1 = tf.nn.relu(tf.add(tf.matmul(input_placeholder, w1), b1))\n",
    "        hidden_output1 = tf.nn.dropout(hidden_output1, keep_prob = keep_prob)\n",
    "\n",
    "    # second hidden layer\n",
    "    with tf.name_scope(\"weight2\") as scope:\n",
    "        w2 = tf.get_variable(\"w2\", shape=[hidden_layer_nodes1, hidden_layer_nodes2], initializer=tf.keras.initializers.he_normal())\n",
    "    with tf.name_scope(\"bias2\") as scope:\n",
    "        b2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes2]))\n",
    "    with tf.name_scope(\"layer2\") as scope:\n",
    "        hidden_output2 = tf.nn.relu(tf.add(tf.matmul(hidden_output1, w2), b2))\n",
    "        hidden_output2 = tf.nn.dropout(hidden_output2, keep_prob = keep_prob)\n",
    "\n",
    "    # third hidden layer\n",
    "    with tf.name_scope(\"weight3\") as scope:\n",
    "        w3 = tf.get_variable(\"w3\", shape=[hidden_layer_nodes2, hidden_layer_nodes3], initializer=tf.keras.initializers.he_normal())\n",
    "    with tf.name_scope(\"bias3\") as scope:\n",
    "        b3 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes3]))\n",
    "    with tf.name_scope(\"layer3\") as scope: \n",
    "        hidden_output3 = tf.nn.relu(tf.add(tf.matmul(hidden_output2, w3), b3))\n",
    "        hidden_output3 = tf.nn.dropout(hidden_output3, keep_prob = keep_prob)\n",
    "        \n",
    "\n",
    "    # output layer\n",
    "    with tf.name_scope(\"weight4\") as scope:\n",
    "        w4 = tf.get_variable(\"w4\", shape=[hidden_layer_nodes3, output_layer_nodes], initializer=tf.keras.initializers.he_normal())\n",
    "    with tf.name_scope(\"bias4\") as scope:\n",
    "        b4 = tf.Variable(tf.random_normal(shape=[output_layer_nodes]))\n",
    "    logits = tf.add(tf.matmul(hidden_output3, w4), b4)\n",
    "    with tf.name_scope(\"output_layer\") as scope:\n",
    "        final_output = tf.nn.softmax(logits)\n",
    "        \n",
    "    return logits, final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost\n",
    "def CostFunction(logits, target_placeholder):\n",
    "    with tf.name_scope(\"cost\") as scope:\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels = target_placeholder))\n",
    "        tf.summary.scalar(\"loss\",loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "def Optimizer(loss, learning_rate):\n",
    "    \n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "def OpenSession():\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def Training(epoch, interval, keep_prob,\n",
    "             input_placeholder, target_placeholder, keep_prob_placeholder,\n",
    "             X_train, y_train,\n",
    "             sess, logdir):\n",
    "    \n",
    "\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    \n",
    "    print('Training the model...')\n",
    "    for i in range(1, (epoch + 1)):\n",
    "        _, summary = sess.run([optimizer, merged_summary], feed_dict = {input_placeholder : X_train, target_placeholder : y_train, keep_prob_placeholder: keep_prob})\n",
    "        writer.add_summary(summary,i)\n",
    "        if i % interval == 0:\n",
    "            print('Epoch', i, '|', 'Loss:', sess.run(loss, feed_dict={input_placeholder : X_train, target_placeholder : y_train, keep_prob_placeholder: keep_prob}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction(mysize, sess, final_output,\n",
    "              input_placeholder, keep_prob_placeholder):\n",
    "    print('Predicted:', (sess.run(final_output, feed_dict={input_placeholder: [mysize], keep_prob_placeholder : 1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(X_test, y_test, sess, final_output,\n",
    "              input_placeholder, keep_prob_placeholder):\n",
    "    count = 0\n",
    "    pred = []\n",
    "    for i in range(len(X_test)):\n",
    "        if np.argmax(y_test[i]) == np.argmax(sess.run(final_output, feed_dict={input_placeholder : [X_test[i]], keep_prob_placeholder:1.0})):\n",
    "            count += 1\n",
    "        pred.append(np.argmax(sess.run(final_output, feed_dict={input_placeholder : [X_test[i]], keep_prob_placeholder:1.0})))\n",
    "#    print('accuracy : ', float(count)/len(X_test))\n",
    "    pred = pd.get_dummies(pred)\n",
    "    pred = np.array(pred)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "\n",
    "test_size = 0.25\n",
    "input_layer_nodes = 6\n",
    "hidden_layer_nodes1 = 30\n",
    "hidden_layer_nodes2 = 30\n",
    "hidden_layer_nodes3 = 30\n",
    "output_layer_nodes =  2\n",
    "\n",
    "learning_rate = 0.01\n",
    "keep_prob = 0.5\n",
    "epoch = 2000\n",
    "interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "('Epoch', 100, '|', 'Loss:', 0.6542043)\n",
      "('Epoch', 200, '|', 'Loss:', 0.6280074)\n",
      "('Epoch', 300, '|', 'Loss:', 0.60743517)\n",
      "('Epoch', 400, '|', 'Loss:', 0.5922809)\n",
      "('Epoch', 500, '|', 'Loss:', 0.58449703)\n",
      "('Epoch', 600, '|', 'Loss:', 0.57491386)\n",
      "('Epoch', 700, '|', 'Loss:', 0.5708803)\n",
      "('Epoch', 800, '|', 'Loss:', 0.5660066)\n",
      "('Epoch', 900, '|', 'Loss:', 0.56511176)\n",
      "('Epoch', 1000, '|', 'Loss:', 0.5679041)\n",
      "('Epoch', 1100, '|', 'Loss:', 0.56427133)\n",
      "('Epoch', 1200, '|', 'Loss:', 0.5611055)\n",
      "('Epoch', 1300, '|', 'Loss:', 0.56290555)\n",
      "('Epoch', 1400, '|', 'Loss:', 0.55988824)\n",
      "('Epoch', 1500, '|', 'Loss:', 0.5626436)\n",
      "('Epoch', 1600, '|', 'Loss:', 0.55886036)\n",
      "('Epoch', 1700, '|', 'Loss:', 0.55997735)\n",
      "('Epoch', 1800, '|', 'Loss:', 0.55922145)\n",
      "('Epoch', 1900, '|', 'Loss:', 0.55962634)\n",
      "('Epoch', 2000, '|', 'Loss:', 0.5584874)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.74      0.73      5169\n",
      "          1       0.73      0.70      0.71      5157\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 혈당 데이터 분석\n",
    "\n",
    "label = '혈색소'\n",
    "\n",
    "X_train, X_test, y_train, y_test, n_input, n_output = formattingData(data_X, data_y, test_size, label)\n",
    "\n",
    "input_placeholder, target_placeholder, keep_prob_placeholder = InitPlaceholders(n_input, n_output)\n",
    "\n",
    "logits, final_output = Create3LayerDNN(input_placeholder,\n",
    "                                       n_input, n_output,\n",
    "                                       input_layer_nodes,\n",
    "                                       hidden_layer_nodes1, hidden_layer_nodes2, hidden_layer_nodes3,\n",
    "                                       output_layer_nodes)\n",
    "\n",
    "loss = CostFunction(logits, target_placeholder)\n",
    "\n",
    "optimizer = Optimizer(loss, learning_rate)\n",
    "\n",
    "sess = OpenSession()\n",
    "\n",
    "Training(epoch, interval, keep_prob,\n",
    "             input_placeholder, target_placeholder, keep_prob_placeholder,\n",
    "             X_train, y_train,\n",
    "             sess, logdir = \"tensorboard/\"+str(label))\n",
    "\n",
    "Evaluation(X_test, y_test, sess, final_output,\n",
    "          input_placeholder, keep_prob_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
